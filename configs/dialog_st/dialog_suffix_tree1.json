{
    "mode": "general_lm_eval",
    "wandb_project": "Knowledge Unlearning Dialog",
    "wandb_run_name": "Suffix-1.3B_32_1",
    "num_train_epochs": 20,
    "check_val_every_n_epoch": 1,
    "check_validation_only": true,
    "do_init_eval": true,
    "train_set": "data/main/lm_extraction_32_1.csv",
    "valid_sets": [
        "validation_data/wizard_of_wikipedia.json",
        "validation_data/empathetic_dialogues.json",
        "validation_data/blended_skill_talk.json",
        "validation_data/wizard_of_internet.json"
    ],
    "valid_subset_path": [
        "",
        "",
        "",
        "",
        ""
    ],
    "valid_type_path": [
        "target",
        "",
        "",
        "",
        ""
    ],
    "train_batch_size": 32,
    "eval_batch_size": 32,
    "gradient_accumulation_steps": 1,
    "ngpu": 1,
    "learning_rate": 5e-5,
    "model_name_or_path": "EleutherAI/gpt-neo-1.3B",
    "el_threshold": 0.0499,
    "ma_threshold": 0.2994,
    "input_length": 512,
    "output_length": 512,
    "target_length": 200,
    "num_workers": 64,
    "strategy": "deepspeed_stage_2_offload",
    "fp16": true,
    "wandb_log": true
}
